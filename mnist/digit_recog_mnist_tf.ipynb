{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb6db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565d46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                         keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                         keras.layers.Dense(10, activation = tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358c12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b12252f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c52b408b7706>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d30143",
   "metadata": {},
   "outputs": [],
   "source": [
    "(td, tl), (tsd,tsl) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc501a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "td, tsd = td/255.0, tsd/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e209980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"acc\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb91ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.4967 - acc: 0.8610 1s - loss\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.1496 - acc: 0.9565\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.1053 - acc: 0.9690 0s - loss: 0.1060 - a\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0773 - acc: 0.9777\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.0628 - acc: 0.9815\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0507 - acc: 0.9852\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.0438 - acc: 0.9865\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0349 - acc: 0.9896\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 815us/step - loss: 0.0311 - acc: 0.9901\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 0.0266 - acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd28f4cf28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callbacks = myCallback()\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(td, tl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc153faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 626us/step - loss: 0.0883 - acc: 0.9732\n"
     ]
    }
   ],
   "source": [
    "hist = model.evaluate(tsd, tsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c53ce68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 775us/step - loss: 0.4347 - accuracy: 0.8765\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.1217 - accuracy: 0.9647\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.0786 - accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.0573 - accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0449 - accuracy: 0.9854\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 728us/step - loss: 0.0354 - accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 723us/step - loss: 0.0274 - accuracy: 0.9916\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    ")\n",
    "    # model fittingreturn history.epoch, history.history['acc'][-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15b9ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 678us/step - loss: 0.5043 - accuracy: 0.8588\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 657us/step - loss: 0.1514 - accuracy: 0.9568\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.1060 - accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 675us/step - loss: 0.0797 - accuracy: 0.9758\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.0636 - accuracy: 0.9797\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 0.0536 - accuracy: 0.9844\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.0452 - accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 691us/step - loss: 0.0373 - accuracy: 0.98850s - loss:\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 666us/step - loss: 0.0297 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 674us/step - loss: 0.0282 - accuracy: 0.9918\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    ")\n",
    "    # model fittingreturn history.epoch, history.history['acc'][-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5883f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.5596 - accuracy: 0.8414\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2013 - accuracy: 0.9422\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.1560 - accuracy: 0.9545\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 618us/step - loss: 0.1268 - accuracy: 0.9637\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.1061 - accuracy: 0.9696\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.0960 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 627us/step - loss: 0.0814 - accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.0777 - accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.0701 - accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.0648 - accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    ")\n",
    "    # model fittingreturn history.epoch, history.history['acc'][-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5f71cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 921us/step - loss: 0.3875 - accuracy: 0.8901\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 873us/step - loss: 0.0994 - accuracy: 0.9699\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 898us/step - loss: 0.0604 - accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 907us/step - loss: 0.0408 - accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 905us/step - loss: 0.0302 - accuracy: 0.9908\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 954us/step - loss: 0.0245 - accuracy: 0.9921\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    ")\n",
    "    # model fittingreturn history.epoch, history.history['acc'][-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dce35885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.9020\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0831 - accuracy: 0.9749\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0496 - accuracy: 0.9843\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0335 - accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\")>=0.99):\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = data.load_data()\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs=10, callbacks=[callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    ")\n",
    "    # model fittingreturn history.epoch, history.history['acc'][-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3333a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
