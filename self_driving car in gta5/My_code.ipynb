{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEL=0\n",
    "# import pytesseract as pyt\n",
    "def straight():\n",
    "#     print('forward')\n",
    "    PressKey(W)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(D)\n",
    "    time.sleep(1)\n",
    "#     ReleaseKey(W)\n",
    "\n",
    "    \n",
    "def left():\n",
    "#     print('left')\n",
    "    PressKey(A)\n",
    "    ReleaseKey(W)\n",
    "    ReleaseKey(D)\n",
    "    time.sleep(1)\n",
    "#     ReleaseKey(A)\n",
    "\n",
    "    \n",
    "def right():\n",
    "#     print('right')\n",
    "    PressKey(D)\n",
    "    ReleaseKey(A)\n",
    "    ReleaseKey(W)\n",
    "    time.sleep(1)\n",
    "#     ReleaseKey(D)\n",
    "    \n",
    "    \n",
    "    \n",
    "def status(o, out):\n",
    "    if(o==0):\n",
    "        return 'left '+str(np.round(out[0],2))+' '+str(np.round(out[1],2))+' '+str(np.round(out[2],2))\n",
    "    if(o==1):\n",
    "        return 'forward'+str(np.round(out[0],2))+' '+str(np.round(out[1],2))+' '+str(np.round(out[2],2))\n",
    "    if(o==2):\n",
    "        return 'right'+str(np.round(out[0],2))+' '+str(np.round(out[1],2))+' '+str(np.round(out[2],2))\n",
    "    \n",
    "    \n",
    "def self_drive():\n",
    "\n",
    "    for i in range(3):\n",
    "        print(i+1)\n",
    "        time.sleep(1)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (50, 50)\n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    \n",
    "    while(True):\n",
    "        screen = pyautogui.screenshot(region=(0,40,800,600))\n",
    "        speed = pyt.image_to_string(screen[600:650, 400:450])\n",
    "        screen = process_image(screen)\n",
    "        x = np.zeros((1, 120,120,1), np.int)\n",
    "        t = cv2.resize(screen,(120,120))\n",
    "        x[:,:,:,0]=t\n",
    "        out = model.predict(x)[0]\n",
    "        o=np.argmax(out)\n",
    "        screen=cv2.putText(screen, status(o,out), org, font, \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('vision',screen)\n",
    "        if(cv2.waitKey(10) & 0xFF==ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if(o==0):\n",
    "            left()\n",
    "        if(o==1 & int(speed)<20):\n",
    "            straight()\n",
    "        if(o==2):\n",
    "            right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Image' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-84ca42bd5bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-e4eb13264d0d>\u001b[0m in \u001b[0;36mself\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mscreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreenshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mspeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m650\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m450\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mscreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Image' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "self_drive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "tester = ImageDataGenerator(rescale=1./255)\n",
    "train_data = train_gen.flow_from_directory('base/train',target_size=(256, 256) ,batch_size=50, class_mode='categorical')\n",
    "test_data = tester.flow_from_directory('base/valid',target_size=(256, 256) ,batch_size=50, class_mode='categorical')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), input_shape=(256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(train_data, epochs=10, validation_data=test_data, steps_per_epoch=90, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist, starting fresh!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Citation: Box Of Hats (https://github.com/Box-Of-Hats )\n",
    "\n",
    "import win32api as wapi\n",
    "import win32con as wcon\n",
    "\n",
    "keyList = [\"\\b\"]\n",
    "for char in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ 123456789,.'Â£$/\\\\\":\n",
    "    keyList.append(char)\n",
    "\n",
    "\n",
    "def key_check():\n",
    "    keys = []\n",
    "    for key in keyList:\n",
    "        if wapi.GetAsyncKeyState(ord(key)):\n",
    "            keys.append(key)\n",
    "    if wapi.GetAsyncKeyState(wcon.VK_UP):\n",
    "        keys.append('up')\n",
    "    if wapi.GetAsyncKeyState(wcon.VK_DOWN):\n",
    "        keys.append('down')\n",
    "    if wapi.GetAsyncKeyState(wcon.VK_RIGHT):\n",
    "        keys.append('right')\n",
    "    if wapi.GetAsyncKeyState(wcon.VK_LEFT):\n",
    "        keys.append('left')\n",
    "    if wapi.GetAsyncKeyState(wcon.VK_SPACE):\n",
    "        keys.append('space')\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "# def keys_to_output(keys):\n",
    "#     \"\"\"\n",
    "#     Convert keys to a ...multi-hot... array\n",
    "#     ['up - 0', 'down - 1', 'left - 2', 'right - 3', 'none - 4']\n",
    "#     \"\"\"\n",
    "#     output = [0, 0, 0, 0, 0]\n",
    "\n",
    "#     if 'left' in keys:\n",
    "#         output[2] = 1\n",
    "#     elif 'up' in keys:\n",
    "#         output[0] = 1\n",
    "#     elif 'down' in keys:\n",
    "#         output[1] = 1\n",
    "#     elif 'right' in keys:\n",
    "#         output[3] = 1\n",
    "#     else:\n",
    "#         output[4] = 1\n",
    "\n",
    "#     return output\n",
    "\n",
    "# create_training_data.py\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def keys_to_output(keys):\n",
    "    '''\n",
    "    Convert keys to a ...multi-hot... array\n",
    "    [A,W,D] boolean values.\n",
    "    '''\n",
    "    output = [0,0,0]\n",
    "    \n",
    "    if 'A' in keys:\n",
    "        output[0] = 1\n",
    "    elif 'D' in keys:\n",
    "        output[2] = 1\n",
    "    else:\n",
    "        output[1] = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "file_name = 'training_data_Long.npy'\n",
    "\n",
    "if os.path.isfile(file_name):\n",
    "    print('File exists, loading previous data!')\n",
    "    training_data = list(np.load(file_name, allow_pickle=True))\n",
    "else:\n",
    "    print('File does not exist, starting fresh!')\n",
    "    training_data = []\n",
    "\n",
    "import PIL\n",
    "\n",
    "def prepare_data(training_data):\n",
    "    \n",
    "    print('starting in: ')\n",
    "    for i in list(range(5))[::-1]:\n",
    "        print(i+1)\n",
    "        time.sleep(1)\n",
    "\n",
    "    \n",
    "    paused = False\n",
    "    time.sleep(5)\n",
    "    while(True):\n",
    "        if not paused:\n",
    "            screen =  pyautogui.screenshot(region=(0,50,800,650))\n",
    "            screen = process_image(screen)\n",
    "            cv2.imshow('rec', screen)\n",
    "            cv2.waitKey(30)\n",
    "            screen = cv2.resize(screen, (160,120))\n",
    "            keys = key_check()\n",
    "            output = keys_to_output(keys)\n",
    "            training_data.append([np.array(screen),np.array(output)])\n",
    "            \n",
    "            if len(training_data) % 500 == 0:\n",
    "                print(len(training_data))\n",
    "                np.save(file_name,training_data)\n",
    "\n",
    "        keys = key_check()\n",
    "        if 'T' in keys or 't' in keys:\n",
    "            \n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            if paused:\n",
    "                paused = False\n",
    "                print('unpaused!')\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                print('Pausing!')\n",
    "                paused = True\n",
    "                time.sleep(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting in: \n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "500\n",
      "Pausing!\n",
      "unpaused!\n",
      "Pausing!\n",
      "unpaused!\n",
      "1000\n",
      "Pausing!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b1a6c7fe521a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-6ded8874344c>\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(training_data)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'T'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m't'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-6ded8874344c>\u001b[0m in \u001b[0;36mkey_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mwapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetAsyncKeyState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetAsyncKeyState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVK_UP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prepare_data(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning (removing extra W inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate(IMAGES, KEYS):\n",
    "    n = len(KEYS)\n",
    "    left=[]\n",
    "    forw=[]\n",
    "    right=[]\n",
    "    for i in range(n):\n",
    "        if(KEYS[i][0]==1):\n",
    "            left.append([IMAGES[i], KEYS[i]])\n",
    "        elif(KEYS[i][1]==1):\n",
    "            forw.append([IMAGES[i], KEYS[i]])\n",
    "        elif(KEYS[i][2]==1):\n",
    "            right.append([IMAGES[i], KEYS[i]])\n",
    "    return left, forw, right\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('training_data.npy', allow_pickle=True)\n",
    "\n",
    "IMAGES=[]\n",
    "KEYS=[]\n",
    "\n",
    "for d in data:\n",
    "    IMAGES.append(d[0])\n",
    "    KEYS.append(d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,f,r = seperate(IMAGES, KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('left', len(l))\n",
    "print('forw', len(f))\n",
    "print('right', len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple(keys):\n",
    "    aw=0\n",
    "    wd=0\n",
    "    for key in keys:\n",
    "        if(key[0]==1 & key[1]==1):\n",
    "            aw=aw+1\n",
    "        elif(key[1]==1 & key[2]==1):\n",
    "            wd=wd+1\n",
    "    return aw, wd\n",
    "\n",
    "\n",
    "print(multiple(KEYS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n=max(len(l),len(r))\n",
    "forward=[]\n",
    "for i in range(n):\n",
    "    forward.append(random.choice(f))\n",
    "\n",
    "l_tr = l[:-500]\n",
    "forward_tr = forward[:-500]\n",
    "r_tr = r[:-500]\n",
    "\n",
    "l_ts = l[-500:]\n",
    "forward_ts = forward[-500:]\n",
    "r_ts = r[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "import os\n",
    "\n",
    "try:\n",
    "    shutil.rmtree('base')\n",
    "    shutil.rmtree('train')\n",
    "    shutil.rmtree('test')\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "base='base/'\n",
    "os.mkdir('base/')\n",
    "train_path = 'base/train/'\n",
    "os.mkdir('base/train')\n",
    "os.mkdir('base/train/0')\n",
    "os.mkdir('base/train/1')\n",
    "os.mkdir('base/train/2')\n",
    "test_path = 'base/test/'\n",
    "os.mkdir('base/test')\n",
    "os.mkdir('base/test/0')\n",
    "os.mkdir('base/test/1')\n",
    "os.mkdir('base/test/2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "for i in range(len(l_tr)):\n",
    "    data = im.fromarray(l_tr[i][0])\n",
    "    data.save(train_path+'0/'+str(i)+'.jpg')\n",
    "    \n",
    "for i in range(len(forward_tr)):\n",
    "    data = im.fromarray(forward_tr[i][0])\n",
    "    data.save(train_path+'1/'+str(i)+'.jpg')\n",
    "    \n",
    "for i in range(len(r_tr)):\n",
    "    data = im.fromarray(r_tr[i][0])\n",
    "    data.save(train_path+'2/'+str(i)+'.jpg')\n",
    "    \n",
    "    \n",
    "for i in range(len(l_ts)):\n",
    "    data = im.fromarray(l_ts[i][0])\n",
    "    data.save(test_path+'0/'+str(i)+'.jpg')\n",
    "    \n",
    "for i in range(len(forward_ts)):\n",
    "    data = im.fromarray(forward_ts[i][0])\n",
    "    data.save(test_path+'1/'+str(i)+'.jpg')\n",
    "    \n",
    "for i in range(len(r_ts)):\n",
    "    data = im.fromarray(r_ts[i][0])\n",
    "    data.save(test_path+'1/'+str(i)+'.jpg')\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "tester = ImageDataGenerator(rescale=1./255)\n",
    "train_data = train_gen.flow_from_directory('train',target_size=(256, 256) ,batch_size=50, class_mode='categorical')\n",
    "test_data = tester.flow_from_directory('valid',target_size=(256, 256) ,batch_size=50, class_mode='categorical')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), input_shape=(256, 256, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.fit(train_data, epochs=10, validation_data=test_data, steps_per_epoch=90, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# import pyautogui\n",
    "data = np.load('training_data_Long.npy', allow_pickle=True)\n",
    "\n",
    "images=[]\n",
    "keys =[]\n",
    "w=120\n",
    "h=120\n",
    "for d in data:\n",
    "    img = cv2.resize(d[0], (w,h))\n",
    "    images.append(img)\n",
    "    keys.append(d[1])\n",
    "    \n",
    "    \n",
    "images = np.array(images)\n",
    "keys = np.array(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as pyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import pyautogui\n",
    "import ctypes\n",
    "\n",
    "SendInput = ctypes.windll.user32.SendInput\n",
    "\n",
    "\n",
    "W = 0x11\n",
    "A = 0x1E\n",
    "S = 0x1F\n",
    "D = 0x20\n",
    "\n",
    "# C struct redefinitions \n",
    "PUL = ctypes.POINTER(ctypes.c_ulong)\n",
    "class KeyBdInput(ctypes.Structure):\n",
    "    _fields_ = [(\"wVk\", ctypes.c_ushort),\n",
    "                (\"wScan\", ctypes.c_ushort),\n",
    "                (\"dwFlags\", ctypes.c_ulong),\n",
    "                (\"time\", ctypes.c_ulong),\n",
    "                (\"dwExtraInfo\", PUL)]\n",
    "\n",
    "class HardwareInput(ctypes.Structure):\n",
    "    _fields_ = [(\"uMsg\", ctypes.c_ulong),\n",
    "                (\"wParamL\", ctypes.c_short),\n",
    "                (\"wParamH\", ctypes.c_ushort)]\n",
    "\n",
    "class MouseInput(ctypes.Structure):\n",
    "    _fields_ = [(\"dx\", ctypes.c_long),\n",
    "                (\"dy\", ctypes.c_long),\n",
    "                (\"mouseData\", ctypes.c_ulong),\n",
    "                (\"dwFlags\", ctypes.c_ulong),\n",
    "                (\"time\",ctypes.c_ulong),\n",
    "                (\"dwExtraInfo\", PUL)]\n",
    "\n",
    "class Input_I(ctypes.Union):\n",
    "    _fields_ = [(\"ki\", KeyBdInput),\n",
    "                 (\"mi\", MouseInput),\n",
    "                 (\"hi\", HardwareInput)]\n",
    "\n",
    "class Input(ctypes.Structure):\n",
    "    _fields_ = [(\"type\", ctypes.c_ulong),\n",
    "                (\"ii\", Input_I)]\n",
    "\n",
    "# Actuals Functions\n",
    "\n",
    "\n",
    "\n",
    "def PressKey(hexKeyCode):\n",
    "    extra = ctypes.c_ulong(0)\n",
    "    ii_ = Input_I()\n",
    "    ii_.ki = KeyBdInput( 0, hexKeyCode, 0x0008, 0, ctypes.pointer(extra) )\n",
    "    x = Input( ctypes.c_ulong(1), ii_ )\n",
    "    ctypes.windll.user32.SendInput(1, ctypes.pointer(x), ctypes.sizeof(x))\n",
    "\n",
    "def ReleaseKey(hexKeyCode):\n",
    "    extra = ctypes.c_ulong(0)\n",
    "    ii_ = Input_I()\n",
    "    ii_.ki = KeyBdInput( 0, hexKeyCode, 0x0008 | 0x0002, 0, ctypes.pointer(extra) )\n",
    "    x = Input( ctypes.c_ulong(1), ii_ )\n",
    "    ctypes.windll.user32.SendInput(1, ctypes.pointer(x), ctypes.sizeof(x))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PressKey(0x11)\n",
    "    time.sleep(1)\n",
    "    ReleaseKey(0x11)\n",
    "    time.sleep(1)\n",
    "\n",
    "def roi(image, vertices):\n",
    "    mask = np.zeros_like(image)\n",
    "    mask = cv2.rectangle(mask, (0,200), (800, 600), 255, -1)\n",
    "#     mask = cv2.rectangle(mask, (0, 450),(180, 600), 0, -1)\n",
    "    masked = cv2.bitwise_and(image, mask)\n",
    "    return masked\n",
    "\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    img = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.Canny(img, threshold1=100, threshold2=250)\n",
    "    \n",
    "    \n",
    "    vertices = [[0,0],[0,200],[800,200],[800,0]]\n",
    "    vertices = np.array(vertices)\n",
    "    img = roi(img, vertices)\n",
    "    \n",
    "    \n",
    "    lines = cv2.HoughLinesP(img, 1, np.pi/180, 150,  None, 10, 0)\n",
    "    img = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    x = np.zeros_like(img)\n",
    "    lines = clean_lines(lines)\n",
    "    \n",
    "    if(lines!=None): \n",
    "#         draw_lines(x, lines)\n",
    "        draw_lines(img, lines)\n",
    "    return img\n",
    "\n",
    "def XY(Y_new,m,c):\n",
    "    X_new = (Y_new-c)//m\n",
    "    if(X_new<0):\n",
    "        X_new=0\n",
    "        Y_new=c\n",
    "    if(X_new>800):\n",
    "        X_new=800\n",
    "        Y_new=m*X_new+c\n",
    "        \n",
    "    return round(X_new), round(Y_new)\n",
    "\n",
    "\n",
    "def clean_lines(lines):\n",
    "    try:\n",
    "        good_lines=[]\n",
    "        for line in lines:\n",
    "            line=line[0]\n",
    "            x,y,X,Y = line\n",
    "            slope_limit = 0.1\n",
    "            m=abs(slope(x,y,X,Y))\n",
    "            if(m<=slope_limit or m>2):\n",
    "                pass\n",
    "            else:\n",
    "                good_lines.append([line])\n",
    "        return good_lines\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "\n",
    "def slope(x,y,X,Y):\n",
    "    num = Y-y\n",
    "    deno = X-x\n",
    "    if(deno==0): return 0\n",
    "    return num/deno\n",
    "\n",
    "\n",
    "def chk(x,y,X,Y):\n",
    "    if(y==200):\n",
    "        if(X<200 or X>600):\n",
    "            return True\n",
    "    if(x==0):\n",
    "        if(y<350):\n",
    "            return True\n",
    "    return False\n",
    "            \n",
    "\n",
    "\n",
    "def draw_lines(img, lines):\n",
    "    for line in lines:\n",
    "        x,y,X,Y = line[0][0],line[0][1],line[0][2],line[0][3]\n",
    "        m=slope(line[0][0],line[0][1],line[0][2],line[0][3])\n",
    "        c=y-m*x\n",
    "        X_new, Y_new = XY(200,m,c)\n",
    "        x_new, y_new = XY(600,m,c)        \n",
    "        if(not chk(x_new,y_new,X_new,Y_new)): cv2.line(img, (x_new,y_new), (X_new,Y_new), [255,255,255], 1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    last_time = time.time()\n",
    "    i=0\n",
    "    while True:\n",
    "        img = pyautogui.screenshot(region=(0,50,800,600))\n",
    "        present = time.time()\n",
    "        while(i<10):\n",
    "            print(\"fps: \",1/(present-last_time))\n",
    "            i=i+1\n",
    "        crop = img.crop((670,465,700,500))\n",
    "        crop = cv2.resize(np.array(crop), (300,350))\n",
    "        cv2.imshow('crop', np.array(crop))\n",
    "          frame = np.array(img)\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        edges = process_image(frame)\n",
    "#         cv2.imshow(\"screenshot\", a)\n",
    "        cv2.imshow('edges', edges)\n",
    "        rec=edges\n",
    "        if (cv2.waitKey(30) == ord(\"q\")):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.expand_dims(images, axis=-1)\n",
    "# keys = np.expand_dims(keys, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((1000, 120,120,1), np.int)\n",
    "x[:,:,:,0]=images\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), input_shape=(120, 120, 1), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit(x, keys, epochs=15, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
